{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec687f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import __main__\n",
    "print(__main__.__package__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7980549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8e1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_cfg = {\n",
    "    \"datasets\": {\n",
    "        \"data_dir\": \"/home/cc/efficient-rsnn-bmi/data/datasets\",\n",
    "        \"ratio_val\": 0.1,\n",
    "        \"random_val\": False,\n",
    "        \"extend_data\": True,\n",
    "        \"sample_duration\": 2.0,\n",
    "        \"remove_segments_inactive\": False,\n",
    "        \"p_drop\": 0.0,\n",
    "        \"p_insert\": 0.0,\n",
    "        \"jitter_sigma\": 0.0,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"dt\": 4e-3,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9e78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "dataloader_cfg = OmegaConf.create(dataloader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c402977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dtype = getattr(torch, dataloader_cfg.datasets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c978e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_rsnn_bmi.core.dataloader import get_dataloader\n",
    "\n",
    "dataloader = get_dataloader(dataloader_cfg, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16157f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from hydra.utils import to_absolute_path\n",
    "\n",
    "model_dir = Path(to_absolute_path(\"./temp_model\")) / \"indy03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1513acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cc/efficient-rsnn-bmi/notebooks/temp_model/indy03\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec72bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'baselineRSNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2e71f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/cc/efficient-rsnn-bmi/notebooks/temp_model/indy03/baselineRSNN-True.pth')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_path = [Path(f) for f in model_dir.iterdir() if model_type in f.name]\n",
    "\n",
    "state_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f4a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"indy_20170131_02.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d343144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indy_20170131_02.mat\n",
      "\u001b[36m[2025-05-21 11:35:08] \u001b[33m[INFO] \u001b[32m[data.neurobench.dataloader] \u001b[37m- Extending data...\u001b[0m\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "train_dat, val_data, test_dat = dataloader.get_single_session_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912bcdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data: 1242\n",
      "Length of val data: 267\n",
      "Length of test data: 1\n",
      "Dimension of 1st spike train data: torch.Size([500, 96])\n",
      "Dimension of 1st of label train data: torch.Size([500, 2])\n",
      "Dimension of 1st spike val data: torch.Size([500, 96])\n",
      "Dimension of 1st of label val data: torch.Size([500, 2])\n",
      "Dimension of 1st spike test data: torch.Size([52116, 96])\n",
      "Dimension of 1st of label test data: torch.Size([52116, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train data: {len(train_dat)}\")\n",
    "print(f\"Length of val data: {len(val_data)}\")\n",
    "print(f\"Length of test data: {len(test_dat)}\")\n",
    "print(f\"Dimension of 1st spike train data: {(train_dat[0][0].shape)}\")\n",
    "print(f\"Dimension of 1st of label train data: {(train_dat[0][1].shape)}\")\n",
    "print(f\"Dimension of 1st spike val data: {(val_data[0][0].shape)}\")\n",
    "print(f\"Dimension of 1st of label val data: {(val_data[0][1].shape)}\")\n",
    "print(f\"Dimension of 1st spike test data: {(test_dat[0][0].shape)}\")\n",
    "print(f\"Dimension of 1st of label test data: {(test_dat[0][1].shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd813c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 1st spike train data: torch.float32\n",
      "Data type of 1st label train data: torch.float32\n",
      "Data type of 1st spike val data: torch.float32\n",
      "Data type of 1st label val data: torch.float32\n",
      "Data type of 1st spike test data: torch.float32\n",
      "Data type of 1st label test data: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data type of 1st spike train data: {train_dat[0][0].dtype}\")\n",
    "print(f\"Data type of 1st label train data: {train_dat[0][1].dtype}\")\n",
    "print(f\"Data type of 1st spike val data: {val_data[0][0].dtype}\")\n",
    "print(f\"Data type of 1st label val data: {val_data[0][1].dtype}\")\n",
    "print(f\"Data type of 1st spike test data: {test_dat[0][0].dtype}\")\n",
    "print(f\"Data type of 1st label test data: {test_dat[0][1].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcaddd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_rsnn_bmi.neurobench.result_handler import BenchmarkResultsHandler\n",
    "\n",
    "results = BenchmarkResultsHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e157ff46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_time_steps = int(dataloader_cfg.datasets.sample_duration / dataloader_cfg.datasets.dt)\n",
    "\n",
    "nb_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cf4dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_outputs = train_dat[0][1].shape[1]\n",
    "\n",
    "nb_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86daddeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_inputs = train_dat[0][0].shape[1]\n",
    "\n",
    "nb_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1f7f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"training\": {\n",
    "        \"batch_size\": 250,\n",
    "        \"SG_beta\": 20,\n",
    "        \"LB_L2_strength\": 100,\n",
    "        \"LB_L2_thresh\": 1e-3,\n",
    "        \"UB_L2_strength\": 0.01,\n",
    "        \"UB_L2_thresh\": 10,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d82a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = OmegaConf.create(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37580993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 4\n",
      "GPU 0: Tesla P100-SXM2-16GB\n",
      "GPU 1: Tesla P100-SXM2-16GB\n",
      "GPU 2: Tesla P100-SXM2-16GB\n",
      "GPU 3: Tesla P100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c5750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5772625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_rsnn_bmi.experiments.models.rsnn.rsnn import BaselineRecurrentSpikingModel\n",
    "\n",
    "model = BaselineRecurrentSpikingModel(\n",
    "    batch_size = training_config.training.batch_size,\n",
    "    nb_time_steps = nb_time_steps,\n",
    "    nb_inputs = nb_inputs,\n",
    "    device = device,\n",
    "    dtype = dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dada4d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model summary\n",
      "\n",
      "## Groups\n",
      "\n",
      "## Connections\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b71d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model\": {\n",
    "        \"stochastic\": False,\n",
    "        \"dropout_p\": 0.3,\n",
    "        \"nb_hidden\": 1,\n",
    "        \"hidden_size\": [64],\n",
    "        \"recurrent\": [True],\n",
    "        \"multiple_readout\": False,\n",
    "        \"tau_mem_readout\": 50e-3,\n",
    "        \"tau_syn_readout\": 10e-3,\n",
    "        \"tau_mem\": 20e-3,\n",
    "        \"tau_syn\": 10e-3,\n",
    "        \"het_timescales\": True,\n",
    "        \"het_timescales_readout\": True,\n",
    "        \"learn_timescales\": True,\n",
    "        \"learn_timescales_readout\": True,\n",
    "        \"delta_synapse\": False,\n",
    "        \"is_half\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9e365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = OmegaConf.create(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e907071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the get activation one\n",
    "import stork\n",
    "\n",
    "activation_function = stork.activations.CustomSpike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e686fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_config.model.stochastic:\n",
    "    activation_function.escape_noise_type = \"sigmoid\"\n",
    "else:\n",
    "    activation_function.escape_noise_type = \"step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43402e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function.escape_noise_params = {\"beta\": training_config.training.SG_beta}\n",
    "activation_function.surrogate_type = \"SuperSpike\"\n",
    "activation_function.surrogate_params = {\"beta\": training_config.training.SG_beta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c89ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202855e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regLB = stork.regularizers.LowerBoundL2(\n",
    "    strength = training_config.training.LB_L2_strength,\n",
    "    threshold = training_config.training.LB_L2_thresh,\n",
    "    dims = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa8c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "regUB = stork.regularizers.UpperBoundL2(\n",
    "    strength = training_config.training.UB_L2_strength,\n",
    "    threshold = training_config.training.UB_L2_thresh,\n",
    "    dims = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b62e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs.append(regLB)\n",
    "regs.append(regUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ad738b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<stork.regularizers.LowerBoundL2 at 0x7f6751ecaf90>,\n",
       " <stork.regularizers.UpperBoundL2 at 0x7f675267da00>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a53760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_input_firing_rates(data, cfg):\n",
    "    mean1 = 0\n",
    "    mean2 = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        mean1 += torch.sum(data[i][0][:, :96]) / cfg.datasets.sample_duration / 96\n",
    "        try:\n",
    "            mean2 += torch.sum(data[i][0][:, 96:]) / cfg.datasets.sample_duration / 96\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    mean1 /= len(data)\n",
    "    mean2 /= len(data)\n",
    "\n",
    "    # For LOCO\n",
    "    print (data[0][0].shape)\n",
    "    if data[0][0].shape[1] == 192:\n",
    "        return mean1, mean2\n",
    "\n",
    "    # FOR INDY\n",
    "    else:\n",
    "        return mean1, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbd8460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 96])\n"
     ]
    }
   ],
   "source": [
    "mean1, mean2 = compute_input_firing_rates(train_dat, dataloader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3871601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6100) None\n"
     ]
    }
   ],
   "source": [
    "print(mean1, mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cab6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializers_config = {\n",
    "    \"initializer\": {\n",
    "        \"compute_nu\": True,\n",
    "        \"sigma_u\": 0.5,\n",
    "        \"nu\": 20,\n",
    "        \"alpha\": 0.9\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9e8280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializers_config = OmegaConf.create(initializers_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d3eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stork.initializers import (\n",
    "    FluctuationDrivenCenteredNormalInitializer,\n",
    "    DistInitializer\n",
    ")\n",
    "\n",
    "hidden_init = FluctuationDrivenCenteredNormalInitializer(\n",
    "    sigma_u=initializers_config.initializer.sigma_u,\n",
    "    nu=mean1,\n",
    "    timestep=dataloader_cfg.datasets.dt,\n",
    "    alpha=initializers_config.initializer.alpha,\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "readout_init = DistInitializer(\n",
    "    dist=torch.distributions.Normal(0, 1),\n",
    "    scaling=\"1/sqrt(k)\",\n",
    "    dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "485d3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stork.nodes import InputGroup\n",
    "\n",
    "input_group = model.add_group(\n",
    "    InputGroup(\n",
    "       shape=nb_inputs,\n",
    "        dropout_p=model_config.model.dropout_p,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "244e37ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputGroup(\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_src_grp = input_group\n",
    "\n",
    "current_src_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "970306c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check this again later after working (CUSTOM READOUT GROUP)\n",
    "\n",
    "from efficient_rsnn_bmi.base.readout import CustomReadoutGroup\n",
    "\n",
    "def get_custom_readouts(cfg):\n",
    "    ro_list = []\n",
    "    for ro, specs in cfg.model[\"readouts\"].items():\n",
    "        if \"tau_mem\" in specs:\n",
    "            tau_mem = specs[\"tau_mem\"]\n",
    "        else:\n",
    "            tau_mem = cfg.model.tau_mem_readout\n",
    "        if \"tau_syn\" in specs:\n",
    "            tau_syn = specs[\"tau_syn\"]\n",
    "        else:\n",
    "            tau_syn = cfg.model.tau_syn_readout\n",
    "\n",
    "        if specs[\"type\"] == \"default\":\n",
    "            ro_group = CustomReadoutGroup(\n",
    "                cfg.data.nb_outputs,\n",
    "                tau_mem=tau_mem,\n",
    "                tau_syn=tau_syn,\n",
    "                het_timescales=cfg.model.het_timescales_readout,\n",
    "                learn_timescales=cfg.model.learn_timescales_readout,\n",
    "                initial_state=-1e-2,\n",
    "                is_delta_syn=False,\n",
    "            )\n",
    "        elif specs[\"type\"] == \"delta\":\n",
    "            ro_group = CustomReadoutGroup(\n",
    "                cfg.data.nb_outputs,\n",
    "                tau_mem=tau_mem,\n",
    "                tau_syn=tau_syn,\n",
    "                het_timescales=cfg.model.het_timescales_readout,\n",
    "                learn_timescales=cfg.model.learn_timescales_readout,\n",
    "                initial_state=-1e-2,\n",
    "                is_delta_syn=True,\n",
    "            )\n",
    "\n",
    "        ro_group.set_name(ro)\n",
    "        ro_list.append(ro_group)\n",
    "\n",
    "    return ro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf4f19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLIFGroup(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "Readout group shape:  (2,)\n",
      "Current source group shape:  (64,)\n",
      "CustomLIFGroup(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ") CustomReadoutGroup()\n"
     ]
    }
   ],
   "source": [
    "from stork.layers import Layer\n",
    "from stork.connections import Connection\n",
    "from efficient_rsnn_bmi.base.lif import CustomLIFGroup\n",
    "from efficient_rsnn_bmi.base.readout import CustomReadoutGroup\n",
    "\n",
    "for i in range (model_config.model.nb_hidden):\n",
    "    hidden_layer = Layer(\n",
    "        name = f\"hidden_{i}\",\n",
    "        model = model,\n",
    "        size = model_config.model.hidden_size[i],\n",
    "        input_group = input_group,\n",
    "        recurrent = model_config.model.recurrent[i],\n",
    "        regs = regs,\n",
    "        neuron_class = CustomLIFGroup,\n",
    "        neuron_kwargs={\n",
    "            \"tau_mem\": model_config.model.tau_mem,\n",
    "            \"tau_syn\": model_config.model.tau_syn,\n",
    "            \"activation\": activation_function,\n",
    "            \"dropout_p\": model_config.model.dropout_p,\n",
    "            \"het_timescales\": model_config.model.het_timescales, # Didn't found\n",
    "            \"learn_timescales\": model_config.model.learn_timescales,\n",
    "            \"is_delta_syn\": model_config.model.delta_synapse, # Didn't found\n",
    "        },\n",
    "    )\n",
    "\n",
    "    current_src_grp = hidden_layer.output_group\n",
    "    print(current_src_grp)\n",
    "\n",
    "    hidden_init.initialize(hidden_layer)\n",
    "\n",
    "    if i == 0 and nb_inputs == 192 and train_dat is not None:\n",
    "        with torch.no_grad():\n",
    "            hidden_layer.connections[0].weight[:, :96] /= mean2 / mean1\n",
    "        \n",
    "    # Add single RO group\n",
    "    readout_group = model.add_group(\n",
    "        CustomReadoutGroup(\n",
    "            nb_outputs,\n",
    "            tau_mem = model_config.model.tau_mem_readout,\n",
    "            tau_syn = model_config.model.tau_syn_readout,\n",
    "            het_timescales = model_config.model.het_timescales_readout,\n",
    "            learn_timescales = model_config.model.learn_timescales_readout,\n",
    "            initial_state = -1e-2,\n",
    "            is_delta_syn = model_config.model.delta_synapse,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"Readout group shape: \", readout_group.shape)\n",
    "    print(\"Current source group shape: \", current_src_grp.shape)\n",
    "    print(current_src_grp, readout_group)\n",
    "    con_ro = model.add_connection(\n",
    "        Connection(current_src_grp, readout_group, dtype=dtype)\n",
    "    )\n",
    "\n",
    "    readout_init.initialize(con_ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "380bc188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model summary\n",
      "\n",
      "## Groups\n",
      "Input, (96,)\n",
      "hidden_0, (64,)\n",
      "Readout, (2,)\n",
      "\n",
      "## Connections\n",
      "Connection(\n",
      "  (src): InputGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (op): Linear(in_features=96, out_features=64, bias=False)\n",
      ")\n",
      "Connection(\n",
      "  (src): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (op): Linear(in_features=64, out_features=64, bias=False)\n",
      ")\n",
      "Connection(\n",
      "  (src): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomReadoutGroup()\n",
      "  (op): Linear(in_features=64, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0c43baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_rsnn_bmi.base.loss import RootMeanSquareError\n",
    "\n",
    "loss_class = RootMeanSquareError()\n",
    "# Mask Early Timestep later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d9c8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stork.optimizers import SMORMS3\n",
    "\n",
    "opt_kwargs = {\n",
    "    \"lr\": 2e-3\n",
    "}\n",
    "\n",
    "opt_kwargs[\"eps\"] = 1e-5 if dtype == torch.float16 else 1e-16\n",
    "\n",
    "opt = SMORMS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41d5ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "scheduler_kwargs = {\"T_max\": 200} # nb of epoch train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe0c74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure this later (Worker Init Seeding)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(42 + worker_id)\n",
    "    random.seed(42 + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf4aa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stork.generators import StandardGenerator\n",
    "\n",
    "generator = StandardGenerator(\n",
    "    nb_workers=2,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e75d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.configure(\n",
    "    input=model.groups[0],\n",
    "    output=model.groups[-1],\n",
    "    loss_stack=loss_class,\n",
    "    generator=generator,\n",
    "    optimizer=opt,\n",
    "    optimizer_kwargs=opt_kwargs,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_kwargs=scheduler_kwargs,\n",
    "    time_step=dataloader_cfg.datasets.dt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edaa8af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model summary\n",
      "\n",
      "## Groups\n",
      "Input, (96,)\n",
      "hidden_0, (64,)\n",
      "Readout, (2,)\n",
      "\n",
      "## Connections\n",
      "Connection(\n",
      "  (src): InputGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (op): Linear(in_features=96, out_features=64, bias=False)\n",
      ")\n",
      "Connection(\n",
      "  (src): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (op): Linear(in_features=64, out_features=64, bias=False)\n",
      ")\n",
      "Connection(\n",
      "  (src): CustomLIFGroup(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (dst): CustomReadoutGroup()\n",
      "  (op): Linear(in_features=64, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "773623e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_state = torch.load(state_dict_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b67d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5005857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52e3ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat.dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52e68fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss_class = RootMeanSquareError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9aca7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for evaluation\n",
    "model.set_nb_steps(test_dat[0][0].shape[0])\n",
    "model.loss_stack = eval_loss_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_rsnn_bmi.neurobench.wrappers.stork_wrapper import StorkModel\n",
    "\n",
    "stork_test_model = StorkModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e2d1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_loader = torch.utils.data.DataLoader(\n",
    "    test_dat,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9294f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x dtype: torch.float16\n",
      "y dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_set_loader:\n",
    "    print(\"x dtype:\", x.dtype)\n",
    "    print(\"y dtype:\", y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64f47bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(test_dat[0][0].dtype)\n",
    "print(test_dat[0][1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a22b4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from neurobench.metrics.workload import R2 as R2Base\n",
    "from neurobench.metrics.utils.decorators import check_shapes\n",
    "\n",
    "class R2(R2Base):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    @check_shapes\n",
    "    def __call__(self, model, preds, data):\n",
    "        self.reset()\n",
    "        labels = data[1].to(preds.device)\n",
    "        self.x_sum_squares += torch.sum(\n",
    "            (labels.squeeze()[:, 0] - preds.squeeze()[:, 0]) ** 2\n",
    "        ).item()\n",
    "        self.y_sum_squares += torch.sum(\n",
    "            (labels.squeeze()[:, 1] - preds.squeeze()[:, 1]) ** 2\n",
    "        ).item()\n",
    "\n",
    "        self.x_labels = self.x_labels.to(labels.device)\n",
    "        self.y_labels = self.y_labels.to(labels.device)\n",
    "\n",
    "        if self.x_labels is None:\n",
    "            self.x_labels = labels.squeeze()[:, 0]\n",
    "            self.y_labels = labels.squeeze()[:, 1]\n",
    "        else:\n",
    "            self.x_labels = torch.cat(\n",
    "                (self.x_labels, labels.squeeze()[:, 0])\n",
    "            )\n",
    "            self.y_labels = torch.cat(\n",
    "                (self.y_labels, labels.squeeze()[:, 1])\n",
    "            )\n",
    "\n",
    "        return self.compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "342e3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurobench.metrics.workload import SynapticOperations as SynapticOperationsBased\n",
    "from neurobench.metrics.utils.layers import single_layer_MACs\n",
    "\n",
    "class SynapticOperations(SynapticOperationsBased):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, model, preds, data):\n",
    "        for hook in model.connection_hooks:\n",
    "            inputs = hook.inputs  # copy of the inputs, delete hooks after\n",
    "            for spikes in inputs:\n",
    "                # spikes is batch, features, see snntorchmodel wrappper\n",
    "                # for single_in in spikes:\n",
    "                if len(spikes) == 1:\n",
    "                    spikes = spikes[0]\n",
    "                hook.hook.remove()\n",
    "                operations, spiking = single_layer_MACs(spikes, hook.layer)\n",
    "                total_ops, _ = single_layer_MACs(spikes, hook.layer, total=True)\n",
    "                self.total_synops += total_ops\n",
    "                if spiking:\n",
    "                    self.AC += operations\n",
    "                else:\n",
    "                    self.MAC += operations\n",
    "                hook.register_hook()\n",
    "        # ops_per_sample = ops / data[0].size(0)\n",
    "        self.total_samples += data[0].squeeze().size(0)\n",
    "        return self.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f14b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurobench.metrics.workload import ActivationSparsity as ActivationSparsityBased\n",
    "\n",
    "class ActivationSparsity(ActivationSparsityBased):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, model, preds, data):\n",
    "        \"\"\"\n",
    "        Compute activation sparsity.\n",
    "\n",
    "        Args:\n",
    "            model: A NeuroBenchModel.\n",
    "            preds: A tensor of model predictions.\n",
    "            data: A tuple of data and labels.\n",
    "        Returns:\n",
    "            float: Activation sparsity\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: for a spiking model, based on number of spikes over all timesteps over all samples from all layers\n",
    "        #       Standard FF ANN depends on activation function, ReLU can introduce sparsity.\n",
    "        total_spike_num = 0  # Count of non-zero activations\n",
    "        total_neuro_num = 0  # Count of all activations\n",
    "\n",
    "        print(model.activation_hooks)\n",
    "        for hook in model.activation_hooks:\n",
    "            # Skip layers with no outputs\n",
    "            print(hook.layer)\n",
    "            if isinstance(hook.layer, CustomLIFGroup):\n",
    "                spikes = hook.layer.get_flattened_out_sequence()\n",
    "                print(spikes)\n",
    "                spikes_num, neuro_num = torch.count_nonzero(spikes).item(), torch.numel(\n",
    "                    spikes\n",
    "                )\n",
    "                total_spike_num += spikes_num\n",
    "                total_neuro_num += neuro_num\n",
    "            else:\n",
    "                for (\n",
    "                    spikes\n",
    "                ) in hook.activation_outputs:  # do we need a function rather than a member\n",
    "                    spike_num, neuro_num = torch.count_nonzero(spikes).item(), torch.numel(\n",
    "                        spikes\n",
    "                    )\n",
    "                    total_spike_num += spike_num\n",
    "                    total_neuro_num += neuro_num\n",
    "\n",
    "        # Compute sparsity\n",
    "        if total_neuro_num == 0:  # Prevent division by zero\n",
    "            return 0.0\n",
    "\n",
    "        sparsity = (total_neuro_num - total_spike_num) / total_neuro_num\n",
    "        return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4df21ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neurobench.metrics.static import (\n",
    "#     Footprint,\n",
    "#     ConnectionSparsity,\n",
    "# )\n",
    "\n",
    "# from neurobench.metrics.workload import (\n",
    "#     # R2,\n",
    "#     ActivationSparsity,\n",
    "#     SynapticOperations,\n",
    "# )\n",
    "\n",
    "# from efficient_rsnn_bmi.neurobench.metrics.r2 import R2\n",
    "\n",
    "# static_metrics = [Footprint, ConnectionSparsity]\n",
    "static_metrics = []\n",
    "# workload_metrics = [R2, ActivationSparsity, SynapticOperations]\n",
    "workload_metrics = [ActivationSparsity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df4ac0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurobench.benchmarks import Benchmark\n",
    "\n",
    "benchmark = Benchmark(\n",
    "    test_model,\n",
    "    test_set_loader,\n",
    "    [],\n",
    "    [],\n",
    "    [static_metrics, workload_metrics],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7814d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hidden_0'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stork_test_model.activation_layers()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d054e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurobench.benchmarks import Benchmark\n",
    "\n",
    "benchmark = Benchmark(\n",
    "    stork_test_model,\n",
    "    test_set_loader,\n",
    "    [],\n",
    "    [],\n",
    "    [static_metrics, workload_metrics],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7df32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:44<00:00, 44.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<neurobench.hooks.neuron.NeuronHook object at 0x7f673cbda9c0>]\n",
      "CustomLIFGroup(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1',\n",
      "       dtype=torch.float16, grad_fn=<ViewBackward0>)\n",
      "\n",
      "Batch num 1/1\n",
      "{'ActivationSparsity': 0.9840278177527055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ActivationSparsity': 0.9840278177527055}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = benchmark.run(verbose=True, device=device)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be343211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def benchmark_in_background():\n",
    "    result = benchmark.run(verbose=True, device=device)\n",
    "\n",
    "    with open(\"benchmark_results_dump.json\", \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "    benchmark.save_benchmark_results(\n",
    "        \"benchmark_results.json\",\n",
    "        \"json\",\n",
    "    )\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [04:10<00:00, 250.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch num 1/1\n",
      "{'R2': 0.7491962909698486, 'ActivationSparsity': 0.0, 'SynapticOperations': {'Effective_MACs': 0.0, 'Effective_ACs': 304.8286898457288, 'Dense': 10368.0}}\n",
      "Results saved to benchmark_results.json.json\n",
      "{'R2': 0.7491962909698486, 'ActivationSparsity': 0.0, 'SynapticOperations': {'Effective_MACs': 0.0, 'Effective_ACs': 304.8286898457288, 'Dense': 10368.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "thread = Thread(target=benchmark_in_background)\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficient-rsnn-bmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
